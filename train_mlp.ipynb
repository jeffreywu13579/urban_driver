{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from tempfile import gettempdir\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import ChunkedDataset, LocalDataManager\n",
    "from l5kit.dataset import EgoDatasetVectorized\n",
    "from l5kit.planning.vectorized.closed_loop_model import VectorizedUnrollModel\n",
    "from l5kit.planning.vectorized.open_loop_model import VectorizedModel\n",
    "from l5kit.vectorization.vectorizer_builder import build_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = \"/home/jeffrey_wu13579/prediction-dataset\"\n",
    "dm = LocalDataManager(None)\n",
    "# get config\n",
    "cfg = load_config_data(\"./config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|   16265    |  4039527   | 320124624  |    38735988   |      112.19     |        248.36        |        79.25         |        24.83         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "# ===== INIT DATASET\n",
    "train_zarr = ChunkedDataset(dm.require(cfg[\"train_data_loader\"][\"key\"])).open()\n",
    "\n",
    "vectorizer = build_vectorizer(cfg, dm)\n",
    "train_dataset = EgoDatasetVectorized(cfg, train_zarr, vectorizer)\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "URBAN_DRIVER = \"Urban Driver\"\n",
    "OPEN_LOOP_PLANNER = \"Open Loop Planner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeffrey_wu13579/miniconda3/lib/python3.9/site-packages/torch/serialization.py:602: UserWarning: 'torch.load' received a zip file that looks like a TorchScript archive dispatching to 'torch.jit.load' (call 'torch.jit.load' directly to silence this warning)\n",
      "  warnings.warn(\"'torch.load' received a zip file that looks like a TorchScript archive\"\n"
     ]
    }
   ],
   "source": [
    "#model_name = URBAN_DRIVER\n",
    "model_name = OPEN_LOOP_PLANNER\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "weights_scaling = [1.0, 1.0, 1.0]\n",
    "\n",
    "_num_predicted_frames = cfg[\"model_params\"][\"future_num_frames\"]\n",
    "_num_predicted_params = len(weights_scaling)\n",
    "\n",
    "\n",
    "if model_name == URBAN_DRIVER:\n",
    "    # TODO\n",
    "    print(\"Not implemented yet\")\n",
    "elif model_name == OPEN_LOOP_PLANNER:\n",
    "    # with ego history\n",
    "    model_path = \"/home/jeffrey_wu13579/l5kit/examples/urban_driver/OL_HS.pt\"\n",
    "    model = torch.load(model_path)\n",
    "else:\n",
    "    raise ValueError(f\"{model_name=} is invalid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeffrey_wu13579/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "train_cfg = cfg[\"train_data_loader\"]\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=train_cfg[\"shuffle\"], batch_size=train_cfg[\"batch_size\"],\n",
    "                              num_workers=train_cfg[\"num_workers\"])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDITED MORE\n",
      "EDITED MORE\n"
     ]
    }
   ],
   "source": [
    "weights_scaling = [1.0, 1.0, 1.0]\n",
    "\n",
    "_num_predicted_frames = cfg[\"model_params\"][\"future_num_frames\"]\n",
    "_num_predicted_params = len(weights_scaling)\n",
    "\n",
    "retrain_model = VectorizedModel(\n",
    "    history_num_frames_ego=cfg[\"model_params\"][\"history_num_frames_ego\"],\n",
    "    history_num_frames_agents=cfg[\"model_params\"][\"history_num_frames_agents\"],\n",
    "    num_targets=_num_predicted_params * _num_predicted_frames,\n",
    "    weights_scaling=weights_scaling,\n",
    "    criterion=nn.L1Loss(reduction=\"none\"),\n",
    "    global_head_dropout=cfg[\"model_params\"][\"global_head_dropout\"],\n",
    "    disable_other_agents=cfg[\"model_params\"][\"disable_other_agents\"],\n",
    "    disable_map=cfg[\"model_params\"][\"disable_map\"],\n",
    "    disable_lane_boundaries=cfg[\"model_params\"][\"disable_lane_boundaries\"],\n",
    ")\n",
    "\n",
    "retrain_optimizer = optim.Adam(retrain_model.parameters(), lr=1e-3)\n",
    "\n",
    "original_model = VectorizedModel(\n",
    "    history_num_frames_ego=cfg[\"model_params\"][\"history_num_frames_ego\"],\n",
    "    history_num_frames_agents=cfg[\"model_params\"][\"history_num_frames_agents\"],\n",
    "    num_targets=_num_predicted_params * _num_predicted_frames,\n",
    "    weights_scaling=weights_scaling,\n",
    "    criterion=nn.L1Loss(reduction=\"none\"),\n",
    "    global_head_dropout=cfg[\"model_params\"][\"global_head_dropout\"],\n",
    "    disable_other_agents=cfg[\"model_params\"][\"disable_other_agents\"],\n",
    "    disable_map=cfg[\"model_params\"][\"disable_map\"],\n",
    "    disable_lane_boundaries=cfg[\"model_params\"][\"disable_lane_boundaries\"],\n",
    ")\n",
    "\n",
    "original_optimizer = optim.Adam(original_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 256])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([36, 1024])\n",
      "torch.Size([36])\n"
     ]
    }
   ],
   "source": [
    "state_dict = model.state_dict()\n",
    "#print(state_dict.keys())\n",
    "print(state_dict['global_head.output_embed.layers.0.weight'].shape)\n",
    "print(state_dict['global_head.output_embed.layers.0.bias'].shape)\n",
    "print(state_dict['global_head.output_embed.layers.1.weight'].shape)\n",
    "print(state_dict['global_head.output_embed.layers.1.bias'].shape)\n",
    "print(state_dict['global_head.output_embed.layers.2.weight'].shape)\n",
    "print(state_dict['global_head.output_embed.layers.2.bias'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load state_dict into original model before clearing output embedding layers\n",
    "original_model.load_state_dict(state_dict.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0234,  0.0293,  0.0122,  ...,  0.0254, -0.0224, -0.0261],\n",
       "        [ 0.0279, -0.0115,  0.0797,  ..., -0.0592, -0.0544, -0.0417],\n",
       "        [ 0.0684, -0.0212, -0.0267,  ..., -0.0593,  0.0273,  0.0177],\n",
       "        ...,\n",
       "        [ 0.0461, -0.0243, -0.0640,  ..., -0.0226, -0.0347, -0.0568],\n",
       "        [-0.0014,  0.0833,  0.0150,  ..., -0.0363,  0.0278,  0.0035],\n",
       "        [ 0.0125,  0.0119,  0.0126,  ..., -0.0202,  0.0529,  0.0520]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset output embedding to initialization state\n",
    "nn.init.zeros_(state_dict['global_head.output_embed.layers.0.bias'])\n",
    "nn.init.zeros_(state_dict['global_head.output_embed.layers.1.bias'])\n",
    "nn.init.zeros_(state_dict['global_head.output_embed.layers.2.bias'])\n",
    "nn.init.kaiming_normal_(state_dict['global_head.output_embed.layers.0.weight'], nonlinearity=\"relu\")\n",
    "nn.init.kaiming_normal_(state_dict['global_head.output_embed.layers.1.weight'], nonlinearity=\"relu\")\n",
    "nn.init.kaiming_normal_(state_dict['global_head.output_embed.layers.2.weight'], nonlinearity=\"relu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrain_model.load_state_dict(state_dict)\n",
    "#print(model.state_dict()['global_from_local.weight'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.8462e-02, -4.5514e-04, -2.9379e-03,  1.3890e-02, -8.1110e-04,\n",
      "         2.1696e-03,  1.3675e-02, -1.4021e-03, -6.7859e-04,  1.3471e-02,\n",
      "         1.6030e-05,  8.6390e-04,  1.3217e-02,  7.7693e-04,  1.8852e-03,\n",
      "         1.3872e-02,  1.7191e-05, -9.5368e-05,  1.7190e-02,  8.6928e-05,\n",
      "         1.1376e-03,  1.4521e-02,  3.8391e-04,  8.2661e-04,  1.7826e-02,\n",
      "        -5.7734e-04,  2.4533e-03,  1.6243e-02,  8.1782e-04, -4.5500e-04,\n",
      "         1.7954e-02,  1.5620e-03, -2.6035e-04,  1.6429e-02,  1.8072e-03,\n",
      "        -9.0915e-04])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(original_model.state_dict()['global_head.output_embed.layers.2.bias'])\n",
    "print(retrain_model.state_dict()['global_head.output_embed.layers.2.bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain_model = retrain_model.to(device)\n",
    "retrain_model.train()\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "for param in retrain_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in retrain_model.global_head.output_embed.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 6\n"
     ]
    }
   ],
   "source": [
    "false_count = 0\n",
    "true_count = 0\n",
    "for param in retrain_model.parameters():\n",
    "    if param.requires_grad:\n",
    "        true_count += 1\n",
    "    else:\n",
    "        false_count += 1\n",
    "print(false_count, true_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0775330513715744 loss(avg): 0.10134446769952773: 100%|██████████| 50/50 [00:10<00:00,  4.84it/s] \n"
     ]
    }
   ],
   "source": [
    "tr_it = iter(train_dataloader)\n",
    "#progress_bar = tqdm(range(cfg[\"train_params\"][\"max_num_steps\"]))\n",
    "progress_bar = tqdm(range(50))\n",
    "losses_train = []\n",
    "\n",
    "for _ in progress_bar:\n",
    "    try:\n",
    "        data = next(tr_it)\n",
    "    except StopIteration:\n",
    "        tr_it = iter(train_dataloader)\n",
    "        data = next(tr_it)\n",
    "    # Forward pass\n",
    "    data = {k: v.to(device) for k, v in data.items()}\n",
    "    result = retrain_model(data)\n",
    "    loss = result[\"loss\"]\n",
    "    # Backward pass\n",
    "    retrain_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    retrain_optimizer.step()\n",
    "\n",
    "    losses_train.append(loss.item())\n",
    "    progress_bar.set_description(f\"loss: {loss.item()} loss(avg): {np.mean(losses_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(progress_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cfg[\"train_params\"][\"max_num_steps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.13090012967586517 loss(avg): 0.13438864499330522: 100%|██████████| 50/50 [00:09<00:00,  5.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# seeing loss on the original model without cleared output embedding\n",
    "original_model = original_model.to(device)\n",
    "original_model.train()\n",
    "torch.set_grad_enabled(True)\n",
    "tr_it = iter(train_dataloader)\n",
    "progress_bar = tqdm(range(50))\n",
    "losses_train = []\n",
    "\n",
    "for _ in progress_bar:\n",
    "    try:\n",
    "        data = next(tr_it)\n",
    "    except StopIteration:\n",
    "        tr_it = iter(train_dataloader)\n",
    "        data = next(tr_it)\n",
    "    # Forward pass\n",
    "    data = {k: v.to(device) for k, v in data.items()}\n",
    "    result = original_model(data)\n",
    "    loss = result[\"loss\"]\n",
    "    # Backward pass\n",
    "    original_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    original_optimizer.step()\n",
    "\n",
    "    losses_train.append(loss.item())\n",
    "    progress_bar.set_description(f\"loss: {loss.item()} loss(avg): {np.mean(losses_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b5b4ab35e453eea6208b330184a4b6bf919a38a7d1673124837a65af97c9e198"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
